{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_MARKERS = (\"src\", \"data\", \"prompts\", \"results\")\n",
    "\n",
    "def find_project_root(start_path):\n",
    "    current = os.path.abspath(start_path)\n",
    "\n",
    "    while True:\n",
    "        if all(os.path.isdir(os.path.join(current, m)) for m in PROJECT_MARKERS):\n",
    "            return current\n",
    "\n",
    "        parent = os.path.dirname(current)\n",
    "        if parent == current:\n",
    "            raise RuntimeError(\"Project root not found\")\n",
    "\n",
    "        current = parent\n",
    "\n",
    "\n",
    "# ---- execution directory (cwd) ----\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# ---- safe starting point ----\n",
    "try:\n",
    "    start_path = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    start_path = cwd\n",
    "\n",
    "\n",
    "# ---- resolve canonical paths ----\n",
    "project_root = find_project_root(start_path)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "src_root     = os.path.join(project_root, \"src\", \"daniel\", \"gemini\")\n",
    "data_root    = os.path.join(project_root, \"data\", \"MAMS-ACSA\", \"raw\", \"data_jsonl\", \"annotated\")\n",
    "schemas_root = os.path.join(project_root, \"data\", \"MAMS-ACSA\", \"raw\", \"data_jsonl\", \"schema\")\n",
    "prompts_root = os.path.join(project_root, \"prompts\", \"daniel\", \"llama\")\n",
    "utils_root   = os.path.join(project_root, \"utils\")\n",
    "results_root = os.path.join(project_root, \"results\", \"daniel\")\n",
    "\n",
    "print(\n",
    "    f\"ðŸ“‚ cwd          : {cwd}\\n\"\n",
    "    f\"ðŸ“‚ Project root : {project_root}\\n\"\n",
    "    f\"ðŸ“‚ Source root  : {src_root}\\n\"\n",
    "    f\"ðŸ“‚ Data root    : {data_root}\\n\"\n",
    "    f\"ðŸ“‚ Prompts root : {prompts_root}\\n\"\n",
    "    f\"ðŸ“‚ Utils root   : {utils_root}\\n\"\n",
    "    f\"ðŸ“‚ Results root : {results_root}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490127d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "train_rows = load_jsonl(Path(data_root) / \"train.jsonl\")\n",
    "val_rows   = load_jsonl(Path(data_root) / \"validation.jsonl\")\n",
    "test_rows  = load_jsonl(Path(data_root) / \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        text = r[\"input\"]\n",
    "        for o in r[\"output\"]:\n",
    "            records.append({\n",
    "                \"text\": text,\n",
    "                \"aspect\": o[\"aspect\"],\n",
    "                \"emotion\": o[\"emotion\"],\n",
    "                \"polarity\": o[\"polarity\"]\n",
    "            })\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47396c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = explode(train_rows)\n",
    "val_df   = explode(val_rows)\n",
    "test_df  = explode(test_rows)\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab821c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"emotion\"] = df[\"emotion\"].replace({\"mentioned_only\": \"neutral\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_encoder = LabelEncoder()\n",
    "polarity_encoder = LabelEncoder()\n",
    "\n",
    "# fit on TRAIN only\n",
    "train_df[\"emotion_id\"]  = emotion_encoder.fit_transform(train_df[\"emotion\"])\n",
    "train_df[\"polarity_id\"] = polarity_encoder.fit_transform(train_df[\"polarity\"])\n",
    "\n",
    "# apply to VAL / TEST\n",
    "val_df[\"emotion_id\"]  = emotion_encoder.transform(val_df[\"emotion\"])\n",
    "val_df[\"polarity_id\"] = polarity_encoder.transform(val_df[\"polarity\"])\n",
    "\n",
    "test_df[\"emotion_id\"]  = emotion_encoder.transform(test_df[\"emotion\"])\n",
    "test_df[\"polarity_id\"] = polarity_encoder.transform(test_df[\"polarity\"])\n",
    "\n",
    "emotion_encoder.classes_, polarity_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "\n",
    "        text = f\"ASPECT: {row['aspect']} | TEXT: {row['text']}\"\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"emotion_labels\": torch.tensor(row[\"emotion_id\"]),\n",
    "            \"polarity_labels\": torch.tensor(row[\"polarity_id\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilroberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_ds = EmotionDataset(train_df, tokenizer)\n",
    "val_ds   = EmotionDataset(val_df, tokenizer)\n",
    "test_ds  = EmotionDataset(test_df, tokenizer)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionPolarityModel(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_polarity):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "\n",
    "        self.emotion_head  = torch.nn.Linear(hidden_size, num_emotions)\n",
    "        self.polarity_head = torch.nn.Linear(hidden_size, num_polarity)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        emotion_labels=None,\n",
    "        polarity_labels=None\n",
    "    ):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        cls_repr = outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        emotion_logits  = self.emotion_head(cls_repr)\n",
    "        polarity_logits = self.polarity_head(cls_repr)\n",
    "\n",
    "        loss = None\n",
    "        if emotion_labels is not None:\n",
    "            loss_emotion = torch.nn.functional.cross_entropy(\n",
    "                emotion_logits, emotion_labels\n",
    "            )\n",
    "            loss_polarity = torch.nn.functional.cross_entropy(\n",
    "                polarity_logits, polarity_labels\n",
    "            )\n",
    "            loss = loss_emotion + 0.3 * loss_polarity\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"emotion_logits\": emotion_logits,\n",
    "            \"polarity_logits\": polarity_logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b906d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    emotion_logits = logits[\"emotion_logits\"]\n",
    "    emotion_labels = labels[\"emotion_labels\"]\n",
    "\n",
    "    preds = np.argmax(emotion_logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"emotion_f1_macro\": f1_score(\n",
    "            emotion_labels,\n",
    "            preds,\n",
    "            average=\"macro\"\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2db23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionPolarityModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_emotions=len(emotion_encoder.classes_),\n",
    "    num_polarity=len(polarity_encoder.classes_)\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=results_root,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab627cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
